---
title: "keyATM Base"
output:
  html_document:
    toc: true
---

```{r setup II, include=FALSE, eval=TRUE}
knitr::opts_chunk$set(eval = TRUE, echo = TRUE)
```

\newcommand{\btheta}{\boldsymbol{\theta}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\balpha}{\boldsymbol{\alpha}}
\newcommand{\bsigma}{\boldsymbol{\sigma}}
\newcommand{\bgamma}{\boldsymbol{\gamma}}
\newcommand{\blambda}{\boldsymbol{\lambda}}
\newcommand{\bphi}{\boldsymbol{\phi}}
\newcommand{\bpsi}{\boldsymbol{\psi}}
\newcommand{\bpi}{\boldsymbol{\pi}}


```{r, include=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(keyATM)
library(quanteda)
library(magrittr)
data(data_corpus_inaugural, package = "quanteda")
data_corpus_inaugural <- head(data_corpus_inaugural, n = 58)

data_tokens <- tokens(data_corpus_inaugural,
                      remove_numbers = TRUE,
                      remove_punct = TRUE,
                      remove_symbols = TRUE,
                      remove_separators = TRUE,
                      remove_url = TRUE) %>%
                 tokens_tolower() %>%
                 tokens_remove(c(stopwords("english"),
                               "may", "shall", "can",
                               "must", "upon", "with", "without")) %>%
                 tokens_select(min_nchar = 3)

data_dfm <- dfm(data_tokens) %>%
               dfm_trim(min_termfreq = 5, min_docfreq = 2)

keywords <- list(Government     = c("laws", "law", "executive"),
                 Congress       = c("congress", "party"),
                 Peace          = c("peace", "world", "freedom"),
                 Constitution   = c("constitution", "rights"),
                 ForeignAffairs = c("foreign", "war"))

keyATM_docs <- keyATM_read(data_dfm)
```

## Preparing documents and keywords
Please read [Preparation](Preparation.html) for the reading of documents and creating a list of keywords.
We use the US Presidential inaugural address data we prapared ([documents](Preparation.html#preparing-texts) and [keywords](Preparation.html#preparing-keywords)).

## Fitting the model

We pass the output of the `keyATM_read` function and
keywords to the `keyATM` function.

Additionally, we need to specify the number of topics
without keywords (the `no_keyword_topics` argument) and model.
Since this example does not use covariates or time stamps, `base` is the appropriate model.

To guarantee the replicability, we recommend to set the random seed
in the `option` argument (see [here](Options.html)
for other options). The default number of iterations is 1,500.

```{r, warning=FALSE, message=FALSE, fig.align='center', results="hide"}
out <- keyATM(
  docs              = keyATM_docs,    # text input
  no_keyword_topics = 5,              # number of topics without keywords
  keywords          = keywords,       # keywords
  model             = "base",         # select the model
  options           = list(seed = 250)
)
```
The default number of iterations is `1500`. Please check [this page](Options.html) for available options.

You can [resume](Resume.html) the iteration by specifying the `resume` argument.


## Saving the model

Once you fit the model, you can save the model with the `saveRDS()` function for replication. We strongly recommend to save the fitted model.
```{r, eval=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
saveRDS(out, file = "SAVENAME.rds")
```

To load the model, you can use `readRDS()` function.
```{r, eval=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
out <- readRDS(file = "SAVENAME.rds")
```

## Interpreting results
There are two main quantities of interest in topic models.
First, topic-word distribution represents the relative frequency of words for each topics, characterizing the topic content.
Second, document-topic distribution represents the proportions of topics for each document, reflecting the main themes of the document and often called topic prevalence.

Since typical corpus contains several thousands of unique terms, we usually scrutinize ten to fifteen words that have high probabilities in a given topic, which is called top words of a topic.

The `top_words()` function returns a table of top words for each of estimated topics.
Keywords assigned to a keyword topic are suffixed with a check mark.
Keywords from another keyword topic are labeled with the topic id of that category.

In the table below, "law", "laws", and "executive" are keywords of the
*Government* topic, while "peace" appears in top words of the *Other_3* topic,
it is a keyword of the *peace* topic.

```{r, warning=FALSE, message=FALSE, fig.align='center'}
top_words(out)
```

Researchers can also examine how likely each topic appears in the corpus
with `plot_topicprop()`.
This function creates a figure that shows the expected proportions of
the corpus belonging to each estimated topic
along with the top three words associated with the topic.
The figure below demonstrates that the ``Peace'' topic is
most likely to appear in the corpus.
```{r, warning=FALSE, message=FALSE, fig.align='center'}
plot_topicprop(out, show_topic = 1:5)
```

To explore documents that are highly associated with each topic, the `top_docs()`
function returns a table of document indexes in which a topic has high proportion.

The table below indicates, for example, that the ninth document in the corpus has the
highest proportion of the *Government* topic among all other documents.

```{r, warning=FALSE, message=FALSE, fig.align='center'}
top_docs(out)
```

Researchers may want to obtain the entire document-topic distribution and
topic-word distribution. The output of the `keyATM()` function contains both
quantities.

```{r, eval = FALSE, warning=FALSE, message=FALSE, fig.align='center'}
out$theta  # Document-topic distribution
out$phi    # Topic-word distribution
```

The **keyATM** provides other functions to diagnose and explore the fitted model.
First, it is important to check the model fitting.
If the model is working as expected, we would observe an increase trend for
the log-likelihood and an decrease trend for the perplexity.

Also the fluctuation of these values get smaller as iteration increases.
The `plot_modelfit()` function visualizes
the within sample log-likelihood and perplexity and the created figure
can be saved with the `save_fig()` function.

```{r, warning = FALSE, message = FALSE}
fig_modelfit <- plot_modelfit(out)
fig_modelfit
```

```{r, eval = FALSE, warning = FALSE, message = FALSE}
save_fig(fig_modelfit, "figures/base_modelfit.pdf", width = 7, height = 5)
```

Furthermore, the **keyATM** can visualize $\balpha$, the prior for the document-topic distribution, and $\bpi$, the probability that each topic uses keyword topic-word distribution.
Values of these parameters should also stabilize over time.

```{r, warning = FALSE, message = FALSE}
plot_alpha(out)
```

```{r, warning = FALSE, message = FALSE}
plot_pi(out)
```

We can use the `save_fig()` function for both the `plot_alpha()` and the `plot_pi()` functions.
