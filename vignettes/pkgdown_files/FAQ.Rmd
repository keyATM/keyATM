---
title: "FAQ"
output:
  html_document:
    toc: true
    toc_depth: 2
---

```{r, include=FALSE, warning=FALSE, message=FALSE, fig.align='center'}
library(keyATM)
library(quanteda)
library(magrittr)
data(data_corpus_inaugural, package = "quanteda")
data_corpus_inaugural <- head(data_corpus_inaugural, n = 58)

data_tokens <- tokens(data_corpus_inaugural,
  remove_numbers = TRUE,
  remove_punct = TRUE,
  remove_symbols = TRUE,
  remove_separators = TRUE,
  remove_url = TRUE
) %>%
  tokens_tolower() %>%
  tokens_remove(c(
    stopwords("english"),
    "may", "shall", "can",
    "must", "upon", "with", "without"
  )) %>%
  tokens_select(min_nchar = 3)

data_dfm <- dfm(data_tokens) %>%
  dfm_trim(min_termfreq = 5, min_docfreq = 2)

keywords <- list(
  Government = c("laws", "law", "executive"),
  Congress = c("congress", "party"),
  Peace = c("peace", "world", "freedom"),
  Constitution = c("constitution", "rights"),
  ForeignAffairs = c("foreign", "war")
)

keyATM_docs <- keyATM_read(data_dfm)
```

# Model

## Which model to use?

The table below summarizes keyATM models and other popular models based on the inputs.

|                                   | Keywords  | Covariate  | Time Structure |
|----------------------------------:|:---------:|:----------:|:--------------:|
|[keyATM Base](keyATM_base.html)  |     ○    |     ×     |        ×      |
|[keyATM Covariate](keyATM_cov.html)|     ○    |     ○     |        △      |
|[keyATM Dynamic](keyATM_dynamic.html)  |     ○    |     ×     |        ○      |
|            LDA Weighted           |     ×    |     ×     |        ×      |
|          LDA Weighted Cov         |     ×    |     ○     |        ×      |
|          LDA Weighted HMM         |     ×    |     ×     |        ○      |
| Latent Dirichlet Allocation (LDA) |     ×    |     ×     |        ×      |
|    Structural Topic Model (STM)   |     ×    |     ○     |        △      |

(○: model incorporates the feature, ×: model does not incorporate the feature, △: model can handle the feature but with some limitations)

The next table compares inference methods and speeds. CGS stands for Collapsed Gibbs Sampling and SS stands for Slice Sampling. Variational inference approximates the target distribution, while CGS and SS sample from the exact distribution.

|                                   |        Inference      |                  Speed                 |
|----------------------------------:|:----------------------|:---------------------------------------|
|[keyATM Base](keyATM_base.html)    |       CGS + SS        |                  Fast                  |
|[keyATM Covariate](keyATM_cov.html)|       CGS + SS / PG   | Moderate  (Depends on # of covariates) |
|[keyATM Dynamic](keyATM_dynamic.html)|        CGS + SS     |                  Fast                  |
|            LDA Weighted           |        CGS + SS       |                  Fast                  |
|          LDA Weighted Cov         |        CGS + SS       |  Moderate (Depends on # of covariates) |
|          LDA Weighted HMM         |        CGS + SS       |                  Fast                  |
| Latent Dirichlet Allocation (LDA) |  Variational EM / CGS |        Depends on implementation       |
|    Structural Topic Model (STM)   |     Variational EM    |               Very Fast                |


# Preprocessing

## Can we use n-grams?
Yes, but you need an extra step in the preprocessing. Let's try a bigram model. You need a tokens object (see [Preparation](Preparation.html)).
Then, **quanteda** will create a n-gram tokens object (see [quanteda's manual](https://tutorials.quanteda.io/basic-operations/tokens/tokens_ngrams/) for details),
```{r, warning=FALSE, message=FALSE, fig.align='center'}
data_tokens_n2 <- tokens_ngrams(data_tokens, n = 2) # bigram
head(data_tokens_n2[[1]], 3)
```

You can pass this preprocessed object to **keyATM** just as the unigram model.
```{r, warning=FALSE, message=FALSE, fig.align='center'}
data_dfm_n2 <- dfm(data_tokens_n2) %>%
  dfm_trim(min_termfreq = 3, min_docfreq = 2)
keyATM_docs_n2 <- keyATM_read(data_dfm_n2)
```

Keywords should respect the n-gram.
```{r, warning=FALSE, message=FALSE, fig.align='center'}
keywords_n2 <- list(
  Government = c("federal_government", "vice_president"),
  People = c("men_women", "fellow_citizens"),
  Peace = c("peace_world")
)
```

Then, you can fit the keyATM models (here we use [the base](keyATM_base.html) model).
```{r, warning=FALSE, message=FALSE, fig.align='center'}
out <- keyATM(
  docs = keyATM_docs_n2, # text input
  no_keyword_topics = 3, # number of topics without keywords
  keywords = keywords_n2, # keywords
  model = "base", # select the model
  options = list(seed = 250)
)
top_words(out, 5)
```

# Keywords


## Can we use a wildcard character in keywords list?

We can use the `dfm_select()` function from the **quanteda** package.
```{r, eval = FALSE, warning=FALSE, message=FALSE}
keyATM_docs <- keyATM_read(texts = data_dfm)

law_all <- colnames(dfm_select(data_dfm, pattern = "law*")) # terms start with `law`
keywords <- list(
  Government     = c(law_all, "executive"),
  Constitution   = c("constitution", "rights"),
  ForeignAffairs = c("foreign", "war")
)
```

Please also consider the `read_keywords()` function to read a dictionary object from quanteda to a named list.


# Fitting

## It takes time to fit the model. What should I do?
Please note that the number of unique words, the total lenght of documents, and the number of topics affect the speed. If you use `cov` model, the number of covariates matters as well, because we need to estimate coefficieitns for covariates.

If you want to speed up fitting, the first thing you can do is to review preprocessing processes. Usually, documents include a lot of low frequency words that do not help interpretation. **quanteda** provides various functions to trim those words.

**keyATM** can [resume fittng](Resume.html).

## Can I run keyATM on cloud computing services?
Yes! For example, [Professor Louis Aslett](http://www.louisaslett.com/) provides an easy to use Amazon Machine Image of RStudio [here](http://www.louisaslett.com/RStudio_AMI/). When you select an instance, please note that **keyATM** does not need multiple cores (one or two cores would be enough because we cannot parallelize Collapsed Gibbs Sampling), but make sure the memory can handle your data.


## Can a theta matrix stored with `store_theta` to `TRUE` directly interpretable as samples from the posterior and thus appropriate for estimating uncertainty?
Yes. Since we use Collapsed Gibbs sampling, thetas are not sampled directly from the posterior distribution. `store_theta` option calculates marginal posterior (Equation 11 in [our paper](https://arxiv.org/pdf/2004.05964.pdf)) for each iteration, so we can use it to consider uncertainty.
