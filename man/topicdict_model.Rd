% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model.R
\name{topicdict_model}
\alias{topicdict_model}
\title{Initialize a topicdict model}
\usage{
topicdict_model(files, dict, covariates_data = NULL,
  covariates_formula = NULL, extra_k = 1, encoding = "UTF-8",
  lowercase = TRUE, remove_numbers = TRUE, remove_punct = TRUE,
  remove_symbols = TRUE, remove_separators = TRUE,
  remove_twitter = FALSE, remove_hyphens = FALSE, remove_url = TRUE,
  stem_language = NULL, stopwords = NULL, alpha = 50/(length(dict) +
  extra_k), beta = 0.01, beta_s = 0.1, gamma_1 = 1, gamma_2 = 1)
}
\arguments{
\item{files}{names of each file to read (or a quanteda corpus object)}

\item{dict}{a quanteda dictionary or named list of character vectors}

\item{covariates_data}{a data.frame or a tibble that is a covariate matrix. Columns are covariates.}

\item{covariates_formula}{formula for the covariates, for example, \code{~.} uses all variables}

\item{extra_k}{number of unseeded topics in addition to the topics seeded by
\code{dict}}

\item{encoding}{File encoding (Default: whatever \code{quanteda} guesses)}

\item{lowercase}{whether to transform each token to lowercase letters}

\item{remove_numbers}{whether to remove numbers}

\item{remove_punct}{whether to remove punctuation}

\item{remove_symbols}{whether to remove non-alphanumerical symbols}

\item{remove_separators}{whether to remove tabs, spaces, newlines, etc.}

\item{remove_twitter}{whether to remove Twitter detritus}

\item{remove_hyphens}{whether to split hyphenated words}

\item{remove_url}{whether to remove URLs}

\item{stem_language}{if not NULL, the language to use for stemming}

\item{stopwords}{if not NULL, a character vector of words to remove,
e.g. \code{quanteda::stopwords("english")}}

\item{alpha}{Starting value for all the model's topic proportion hyperparameters. Default: 50 / number of topics)}

\item{beta}{Hyperparameter for estimated word probabilities. Default: 0.01}

\item{beta_s}{Hyperparameter for seeded word probabilities. Default: 0.1}

\item{gamma_1}{First Beta hyperparameter for probability of being drawn from a seeded topic. Default: 1.0}

\item{gamma_2}{Second Beta hyperparameter for probability of being drawn from a seeded topic. Default: 1.0}
}
\value{
A list containing \describe{
        \item{W}{a list of vectors of word indexes}
        \item{Z}{a list of vectors of topic indicators isomorphic to W}
        \item{C}{a covariate matrix is there is an input}
        \item{X}{a list of vectors of seed indicators (0/1) isomorphic to W}
        \item{vocab}{a vector of vocabulary items}
        \item{files}{a vector of document filenames}
        \item{dict}{a tokenized version of the dictionary}
        \item{seeds}{a list of words for the seed words in dict, named by dictionary category}
        \item{extra_k}{how many extra non-seeded topics are required}
        \item{alpha}{a vector of topic proportion hyperparameters. If you use the model with covariates, it is not used.}
        \item{alpha_iter}{a list to store topic proportion hyperparameters}
        \item{Lambda_iter}{a list to store coefficients of the covariates}
        \item{sampling_info}{information related to sampling}
        \item{model_fit}{a list to store perplexity and log-likelihood}
        \item{gamma1}{First prior probability parameter for X (currently the same for all topics)}
        \item{gamma2}{Second prior probability parameter for X (currently the same for all topics)}
        \item{beta}{prior parameter for the non-seeded word generation probabilities}
        \item{beta_s}{prior parameter for the seeded word generation probabilities}
        \item{use_cov}{boolean, whether or not use the covariate}
        \item{call}{details of the function call}
        }.
}
\description{
This function creates a list of word indexes W, topic indicators Z,
seed indicators X, a vocabulary list \code{vocab} from \code{files}.
}
\details{
\code{Z} represents which topic a word topken was generated by.
It is initialized randomly
from \code{length(dict) + extra_k} topics, except when \code{dict}
assigns a word to a particular category, in which case this topic
indicator is assigned.
For example, if a word appears in the second category of \code{dict}
it will always be initialized as 1.

\code{X} is 1 when a word is generated from one of the topics from
the dictionary ('seeded') and 0 when it was generated from one of
the \code{extra_k} normal topics. \code{X} is initialized randomly
except when the word is contained in \code{dict}.

Note that all indicators are zero-based for ease of later processing
in C++, so \code{mod$vocab[mod$W + 1]} recovers the (tokenized) words
of the i-th document from model \code{mod}.

If \code{alpha} is a scalar this is the value given to all elements of
alpha. If it is a vector of the correct length those values are used
as the starting alphas.
}
